{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVID PS and RX dataset analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from typing import Any, Dict, List, Tuple\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths to data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/Users/manuel/Desktop/BiomedDataAnalysisCourse/project/data/\"\n",
    "ps_rx_fname = os.path.join(data_path, \"merged_data_processed_corrected.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define functions used throughout the analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_age(birth_year: int, visit_year: int) -> int:\n",
    "    assert isinstance(birth_year, int)\n",
    "    assert isinstance(visit_year, int)\n",
    "    assert birth_year < visit_year\n",
    "    age = visit_year - birth_year\n",
    "    return age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_column(column_data: pd.Series, dtype: str) -> List[Any]:\n",
    "    assert isinstance(column_data, pd.Series)\n",
    "    assert isinstance(dtype, str)\n",
    "    if dtype == \"categorical\":\n",
    "        most_freq = column_data.describe()[\"top\"]\n",
    "        column_data.fillna(most_freq, inplace=True)\n",
    "    elif dtype == \"numerical\":\n",
    "        mean_val = column_data.describe()[\"mean\"]\n",
    "        column_data.fillna(mean_val, inplace=True)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown data type ({dtype})\")\n",
    "    return column_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_column(column_data: pd.Series) -> List[float]:\n",
    "    assert isinstance(column_data, pd.Series)\n",
    "    norm_data = [None] * len(column_data)\n",
    "    column_data = column_data.tolist()\n",
    "    for i,v in enumerate(column_data):\n",
    "        norm_data[i] = (column_data[i] - min(column_data)) / (max(column_data) - min(column_data))\n",
    "    assert len(norm_data) == len(column_data)\n",
    "    return norm_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_column(column_data: pd.Series) -> List[float]:\n",
    "    assert isinstance(column_data, pd.Series)\n",
    "    std_data = [None] * len(column_data)\n",
    "    column_data = column_data.tolist()\n",
    "    for i,v in enumerate(column_data):\n",
    "        std_data[i] = (column_data[i] - np.mean(column_data)) / np.std(column_data)\n",
    "    assert len(std_data) == len(column_data)\n",
    "    return std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_measures(column_data: pd.Series) -> List[float]:\n",
    "    assert isinstance(column_data, pd.Series)\n",
    "    corrected_data = []\n",
    "    for v in column_data.tolist():\n",
    "        if str(v) == \"nan\":\n",
    "            corrected_data.append(v)\n",
    "        else:\n",
    "            fields = v.split(\"10^9\")\n",
    "            value = float(fields[0].replace(\",\", \".\"))\n",
    "            corrected_data.append(value)\n",
    "    assert len(column_data) == len(corrected_data)\n",
    "    return corrected_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and visualize the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_rx_df = pd.read_csv(ps_rx_fname, delimiter=\";\", decimal=\",\")\n",
    "ps_rx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove units of measure from some columns of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\n",
    "    \"FIELDSET_PS-BLOOD_COUNT_LEUCOCITI\", \"FIELDSET_PS-BLOOD_COUNT_NEUTROFILI\"\n",
    "]:\n",
    "    ps_rx_df[col] = remove_measures(ps_rx_df[col])\n",
    "ps_rx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocessing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute patients age at ER visit time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_rx_df[\"AGE\"] = ps_rx_df.apply(lambda x : compute_age(int(x[1]), int(x[-1].split(\"/\")[-1])), axis=1)\n",
    "ps_rx_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop columns not used throughout the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\n",
    "    \"BIRTHDAY\",\n",
    "    \"DEAD_DATE\",\n",
    "    \"STOP\",\n",
    "    \"START\",\n",
    "    \"CODE\"\n",
    "]\n",
    "ps_rx_df.drop(drop_cols, axis=1, inplace=True)\n",
    "ps_rx_df.head()  # 769 visits and 89 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set visit ID as DataFrame index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps_rx_df.index = ps_rx_df.ID.tolist()\n",
    "ps_rx_df.drop([\"ID\"], axis=1, inplace=True)\n",
    "ps_rx_df.head()  # 88 variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recover training data and the response we want predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = ps_rx_df.drop([\"DEATH\"], axis=1)\n",
    "Y = ps_rx_df[\"DEATH\"]\n",
    "X.head()  # training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()  # response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encode categorical variables in the dataset. For encoding we'll use `OrdinalEncoder` function from the `sklearn` Python package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill NaN rows for each categorical variable using the most frequent value\n",
    "cat_vars = X.select_dtypes([\"object\"]).columns.tolist()\n",
    "for cat_var in cat_vars:\n",
    "    X[cat_var] = fillna_column(X[cat_var], \"categorical\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fill NaN rows for each numerical variable using the mean value\n",
    "num_vars = list(set(X.columns.tolist()).difference(set(cat_vars)))\n",
    "for num_var in num_vars:\n",
    "    X[num_var] = fillna_column(X[num_var], \"numerical\")\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# categorical variables encoding\n",
    "X_cat = X[cat_vars]\n",
    "enc = OrdinalEncoder()\n",
    "X[cat_vars] = enc.fit_transform(X_cat)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize our dataset using dimensionality reduction via PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)  # use 2 components\n",
    "pcs = pca.fit_transform(X)\n",
    "X_pcs = pd.DataFrame(\n",
    "    data=pcs, columns=[f\"PC{i}\" for i in range(1,3)], index=X.index.tolist()\n",
    ")\n",
    "f, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", ax=ax)\n",
    "ax.set_xlabel(\"PC1\", size=16)\n",
    "ax.set_ylabel(\"PC2\", size=16)\n",
    "ax.set_title(\"Original data\", size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some strong outliers in our dataset. We should remove them before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visits_to_remove = X_pcs[ \n",
    "    (X_pcs.PC1 > 3500) | (X_pcs.PC2 > 1000) \n",
    "].index.tolist()\n",
    "X.drop(visits_to_remove, axis=0, inplace=True)\n",
    "# adjust Y vector accordingly\n",
    "Y.drop(visits_to_remove, axis=0, inplace=True)\n",
    "# recompute PCs\n",
    "pcs = pca.fit_transform(X)\n",
    "X_pcs = pd.DataFrame(\n",
    "    data=pcs, columns=[f\"PC{i}\" for i in range(1,3)], index=X.index.tolist()\n",
    ")\n",
    "# plot PCA\n",
    "f, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", ax=ax)\n",
    "ax.set_xlabel(\"PC1\", size=16)\n",
    "ax.set_ylabel(\"PC2\", size=16)\n",
    "ax.set_title(\"Original data\", size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize data\n",
    "X_std = pd.DataFrame()\n",
    "for col in X.columns.tolist():\n",
    "    X_std[col] = standardize_column(X[col])\n",
    "# compute PCs\n",
    "pcs = pca.fit_transform(X_std)\n",
    "X_pcs = pd.DataFrame(\n",
    "    data=pcs, columns=[f\"PC{i}\" for i in range(1,3)], index=X_std.index.tolist()\n",
    ")\n",
    "# plot PCA\n",
    "f, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", ax=ax)\n",
    "ax.set_xlabel(\"PC1\", size=16)\n",
    "ax.set_ylabel(\"PC2\", size=16)\n",
    "ax.set_title(\"Original data\", size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset in [0,1]\n",
    "X_norm = pd.DataFrame()\n",
    "for col in X.columns.tolist():\n",
    "    X_norm[col] = normalize_column(X[col])\n",
    "# compute PCs\n",
    "pcs = pca.fit_transform(X_norm)\n",
    "X_pcs = pd.DataFrame(\n",
    "    data=pcs, columns=[f\"PC{i}\" for i in range(1,3)], index=X_norm.index.tolist()\n",
    ")\n",
    "# plot PCA\n",
    "f, ax = plt.subplots(1,1,figsize=(20,10))\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", ax=ax)\n",
    "ax.set_xlabel(\"PC1\", size=16)\n",
    "ax.set_ylabel(\"PC2\", size=16)\n",
    "ax.set_title(\"Original data\", size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unsupervised classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform k-means clustering\n",
    "kmeans = KMeans(n_clusters=2, init=\"random\", max_iter=150, random_state=0)\n",
    "labels_orig = kmeans.fit_predict(X)\n",
    "labels_orig = [np.abs(l - 1) for l in labels_orig]\n",
    "# visualize results \n",
    "pca = PCA(n_components=2)\n",
    "pcs = pca.fit_transform(X)\n",
    "X_pcs = pd.DataFrame(\n",
    "    data=pcs, columns=[f\"PC{i}\" for i in range(1,3)], index=X.index.tolist()\n",
    ")\n",
    "X_pcs[\"Cluster\"] = labels_orig\n",
    "X_pcs[\"Death\"] = Y.tolist()\n",
    "f, (ax1, ax2) = plt.subplots(1,2,figsize=(20,10))\n",
    "palette=[\"#D3880E\", \"#3B1375\"]\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", palette=palette, hue=\"Death\", ax=ax1)\n",
    "ax1.set_xlabel(\"PC1\", size=16)\n",
    "ax1.set_ylabel(\"PC2\", size=16)\n",
    "ax1.set_title(\"Original data\", size=18)\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", palette=palette, hue=\"Cluster\", ax=ax2)\n",
    "ax2.set_xlabel(\"PC1\", size=16)\n",
    "ax2.set_ylabel(\"PC2\", size=16)\n",
    "ax2.set_title(\"K-means clustering\", size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform k-means clustering\n",
    "kmeans = KMeans(n_clusters=2, init=\"random\", max_iter=150, random_state=0)\n",
    "labels_norm = kmeans.fit_predict(X_norm)\n",
    "#labels_norm = [np.abs(l - 1) for l in labels_norm]\n",
    "# visualize results \n",
    "pca = PCA(n_components=2)\n",
    "pcs = pca.fit_transform(X_norm)\n",
    "X_pcs = pd.DataFrame(\n",
    "    data=pcs, columns=[f\"PC{i}\" for i in range(1,3)], index=X_norm.index.tolist()\n",
    ")\n",
    "X_pcs[\"Cluster\"] = labels_norm\n",
    "X_pcs[\"Death\"] = Y.tolist()\n",
    "f, (ax1, ax2) = plt.subplots(1,2,figsize=(20,10))\n",
    "palette=[\"#D3880E\", \"#3B1375\"]\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", palette=palette, hue=\"Death\", ax=ax1)\n",
    "ax1.set_xlabel(\"PC1\", size=16)\n",
    "ax1.set_ylabel(\"PC2\", size=16)\n",
    "ax1.set_title(\"Original data\", size=18)\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", palette=palette, hue=\"Cluster\", ax=ax2)\n",
    "ax2.set_xlabel(\"PC1\", size=16)\n",
    "ax2.set_ylabel(\"PC2\", size=16)\n",
    "ax2.set_title(\"K-means clustering\", size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform k-means clustering\n",
    "kmeans = KMeans(n_clusters=2, init=\"random\", max_iter=150, random_state=0)\n",
    "labels_std = kmeans.fit_predict(X_std)\n",
    "labels_std = [np.abs(l - 1) for l in labels_std]\n",
    "# visualize results \n",
    "pca = PCA(n_components=2)\n",
    "pcs = pca.fit_transform(X_std)\n",
    "X_pcs = pd.DataFrame(\n",
    "    data=pcs, columns=[f\"PC{i}\" for i in range(1,3)], index=X_std.index.tolist()\n",
    ")\n",
    "X_pcs[\"Cluster\"] = labels_std\n",
    "X_pcs[\"Death\"] = Y.tolist()\n",
    "f, (ax1, ax2) = plt.subplots(1,2,figsize=(20,10))\n",
    "palette=[\"#D3880E\", \"#3B1375\"]\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", palette=palette, hue=\"Death\", ax=ax1)\n",
    "ax1.set_xlabel(\"PC1\", size=16)\n",
    "ax1.set_ylabel(\"PC2\", size=16)\n",
    "ax1.set_title(\"Original data\", size=18)\n",
    "sns.scatterplot(data=X_pcs, x=\"PC1\", y=\"PC2\", palette=palette, hue=\"Cluster\", ax=ax2)\n",
    "ax2.set_xlabel(\"PC1\", size=16)\n",
    "ax2.set_ylabel(\"PC2\", size=16)\n",
    "ax2.set_title(\"K-means clustering\", size=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "print(\"\\nOriginal data\\n\")\n",
    "f1 = f1_score(Y, labels_orig, average=\"binary\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "\n",
    "# normalized data\n",
    "print(\"\\nNormalized data\\n\")\n",
    "f1 = f1_score(Y, labels_norm, average=\"binary\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "\n",
    "# standardized data\n",
    "print(\"\\nStandardized data\\n\")\n",
    "f1 = f1_score(Y, labels_std, average=\"binary\")\n",
    "print(f\"F1-score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "print(\"\\nOriginal data\\n\")\n",
    "for n in range(3, 11):\n",
    "    # split dataset in training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test_orig = train_test_split(\n",
    "        X, Y, test_size=0.25 \n",
    "    )\n",
    "    # use KNN\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "    neigh.fit(X_train, Y_train)\n",
    "    predictions_orig = neigh.predict(X_test)\n",
    "    f1 = f1_score(predictions_orig, Y_test_orig, average=\"binary\") \n",
    "    print(f\"F1-score ({n} neighbors): {f1}\")\n",
    "\n",
    "# normalized data\n",
    "print(\"\\nNormalized data\\n\")\n",
    "for n in range(3, 11):\n",
    "    # split dataset in training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test_norm = train_test_split(\n",
    "        X_norm, Y, test_size=0.25 \n",
    "    )\n",
    "    # use KNN\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "    neigh.fit(X_train, Y_train)\n",
    "    predictions_norm = neigh.predict(X_test)\n",
    "    f1 = f1_score(predictions_norm, Y_test_norm, average=\"binary\") \n",
    "    print(f\"F1-score ({n} neighbors): {f1}\")\n",
    "\n",
    "# standardized data\n",
    "print(\"\\nStandardized data\\n\")\n",
    "for n in range(3, 11):\n",
    "    # split dataset in training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test_std = train_test_split(\n",
    "        X_std, Y, test_size=0.25 \n",
    "    )\n",
    "    # use KNN\n",
    "    neigh = KNeighborsClassifier(n_neighbors=n)\n",
    "    neigh.fit(X_train, Y_train)\n",
    "    predictions_std = neigh.predict(X_test)\n",
    "    f1 = f1_score(predictions_std, Y_test_std, average=\"binary\") \n",
    "    print(f\"F1-score ({n} neighbors): {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data\n",
    "print(\"\\nOriginal data\\n\")\n",
    "X_train, X_test, Y_train, Y_test_orig = train_test_split(\n",
    "        X, Y, test_size=0.25\n",
    ")\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, Y_train)\n",
    "predictions_orig = clf.predict(X_test)\n",
    "f1 = f1_score(predictions_orig, Y_test_orig, average=\"binary\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "# normalized data\n",
    "print(\"\\nNormalized data\\n\")\n",
    "X_train, X_test, Y_train, Y_test_norm = train_test_split(\n",
    "        X_norm, Y, test_size=0.25\n",
    ")\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, Y_train)\n",
    "predictions_norm = clf.predict(X_test)\n",
    "f1 = f1_score(predictions_norm, Y_test_norm, average=\"binary\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "# standardized data\n",
    "# original data\n",
    "print(\"\\nStandardized data\\n\")\n",
    "X_train, X_test, Y_train, Y_test_std = train_test_split(\n",
    "        X_std, Y, test_size=0.25\n",
    ")\n",
    "clf = LogisticRegression(random_state=0).fit(X_train, Y_train)\n",
    "predictions_std = clf.predict(X_test)\n",
    "f1 = f1_score(predictions_std, Y_test_std, average=\"binary\")\n",
    "print(f\"F1-score: {f1}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
